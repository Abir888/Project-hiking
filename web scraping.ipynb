{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.common.by import By\n",
    "import time\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_hiking_project_trails(url):\n",
    "    # Set up Chrome WebDriver \n",
    "    chrome_options = webdriver.ChromeOptions()\n",
    "    chrome_options.add_argument(\"--headless=new\")\n",
    "    \n",
    "    \n",
    "    driver = webdriver.Chrome( options=chrome_options)\n",
    "    \n",
    "\n",
    "    # Open the webpage\n",
    "    driver.get(url)\n",
    "    \n",
    "    def scroll_to_bottom():\n",
    "        driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "        time.sleep(3)  # You may adjust the sleep time based on your page loading speed\n",
    "        \n",
    "    while True:\n",
    "        try:\n",
    "            show_more_button = WebDriverWait(driver, 15).until(EC.element_to_be_clickable((By.ID, \"load-more-trails\")))\n",
    "            show_more_button.click()\n",
    "        except:\n",
    "            scroll_to_bottom()\n",
    "        else:\n",
    "            scroll_to_bottom()\n",
    "            \n",
    "            \n",
    "            # Check if the \"Show More\" button is still present\n",
    "        is_button_present = len(driver.find_elements(By.ID, \"load-more-trails\")) > 0\n",
    "        if not is_button_present:\n",
    "            break\n",
    "            \n",
    "\n",
    "\n",
    "    content = driver.page_source\n",
    "    driver.quit()\n",
    "\n",
    "    soup = BeautifulSoup(content, \"html.parser\")\n",
    "    trails = soup.find_all(\"tr\", class_=\"trail-row\")\n",
    "    trails_info_list = []\n",
    "\n",
    "    for trail in trails:\n",
    "        trail_url = trail[\"data-href\"]\n",
    "        length_km = trail.find(\"span\", class_=\"metric\").text.strip().replace(\"\\n    km\", \"\")\n",
    "        trail_title = trail.find(\"a\", class_=\"text-black\").text.strip()\n",
    "        difficulty = trail.find(\"span\", class_=\"difficulty-text text-white align-middle\").text\n",
    "        city = trail.find(\"div\", class_=\"float-xs-right\").text.strip()\n",
    "        nb_reviews = trail.find(\"td\", class_=\"hidden-sm-down text-muted small\").text.strip()\n",
    "        score_card = trail.find(\"span\", class_=\"scoreStars\")\n",
    "        score = []\n",
    "\n",
    "        for star_img in score_card.find_all(\"img\"):\n",
    "            star_ob = star_img[\"src\"]\n",
    "            score.append(star_ob)\n",
    "\n",
    "        s = 5\n",
    "        n = 4\n",
    "\n",
    "        while n < len(score) and n > -1:\n",
    "            if score[n] == \"/img/stars/starRed.svg\":\n",
    "                break\n",
    "            else:\n",
    "                s -= 1\n",
    "                n -= 1\n",
    "\n",
    "        trails_info = {\n",
    "            \"name\": trail_title,\n",
    "            \"city\": city,\n",
    "            \"length (km)\": length_km,\n",
    "            \"difficulty\": difficulty,\n",
    "            \"review score\": s,\n",
    "            \"number of reviews\": nb_reviews,\n",
    "            \"trail url\": trail_url\n",
    "        }\n",
    "        trails_info_list.append(trails_info)\n",
    "\n",
    "    df_trails = pd.DataFrame(trails_info_list)\n",
    "    return df_trails\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_data_from_multiple_pages(base_url):\n",
    "    country_url = []\n",
    "    \n",
    "    country_page = requests.get(base_url)\n",
    "    soup_country = BeautifulSoup(country_page.text, \"html.parser\")\n",
    "    countries = soup_country.find_all(\"div\",class_=\"onx-directory__item area\")\n",
    "    \n",
    "    \n",
    "    for country in countries:\n",
    "        c_url = country.find(\"a\")[\"href\"]\n",
    "        country_url.append(c_url)\n",
    "        \n",
    "    all_trails = []\n",
    "        \n",
    "    for c in country_url:\n",
    "        #print(c)\n",
    "        country_trail = scrape_hiking_project_trails(c)\n",
    "        all_trails.append(country_trail)\n",
    "        \n",
    "       \n",
    "        \n",
    "    data = pd.concat(all_trails, ignore_index = True)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all = scrape_data_from_multiple_pages(\"https://www.hikingproject.com\")\n",
    "all.to_csv(\"all_hiking_places.csv\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
